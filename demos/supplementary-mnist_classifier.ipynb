{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import json\n",
    "\n",
    "project_root = os.path.abspath(\"\")  # alternative\n",
    "if project_root[-12:] == 'LyoSavin2023':\n",
    "    base_dir = project_root\n",
    "else:\n",
    "    base_dir = os.path.dirname(project_root)\n",
    "sys.path.append(os.path.join(base_dir, 'core'))\n",
    "sys.path.append(os.path.join(base_dir, 'core/utils'))\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from utils import remove_all_ticks_and_labels\n",
    "\n",
    "global device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = {\n",
    "    'model_name': 'large-noisy-image-classifier',\n",
    "    'model_num': 6,\n",
    "    'num_hidden': 32,\n",
    "    'dataset': 'mnist',\n",
    "    'num_epochs': 1e2,\n",
    "    'lr': 1e-2,\n",
    "    'num_steps': 150,\n",
    "    'batch_size': 512,\n",
    "    'num_in': 28*28,\n",
    "    'schedule': 'sigmoid',\n",
    "    'start': 1e-7,\n",
    "    'end': 1e-1,\n",
    "}\n",
    "# save description\n",
    "with open(os.path.join(base_dir, 'core', 'model_description', f'{description[\"model_name\"]}_{description[\"model_num\"]}.json'), 'w') as f:\n",
    "    json.dump(description, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "mnist_dir = os.path.join(base_dir, 'core', 'datasets', 'mnist')\n",
    "\n",
    "mnist_train = datasets.MNIST(mnist_dir, train=True, download=True,\n",
    "                transform=transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # transforms.Normalize((0.1307,), (0.3081,))\n",
    "                ]))\n",
    "\n",
    "# mnist_train.targets\n",
    "print(mnist_train[0][1])\n",
    "\n",
    "# ------------------------------- select digits ------------------------------ #\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    mnist_train,\n",
    "    batch_size=description['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50ffed4ddfc4ade8874274d3e9ba013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training model:   0%|          | 0/100 [00:00<?, ?epochs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training is over at last\n",
      "model state dict saved in directory: /mnt/ceph/users/blyo1/projects/LyoSavin2023/core/saved_weights/large-noisy-image-classifier_6.pt\n"
     ]
    }
   ],
   "source": [
    "# training \n",
    "from image_utils import generate_many_noisy_samples, rescale_to_neg_one_to_one\n",
    "global device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}', flush=True)\n",
    "\n",
    "def classifier_loss(model, x, labels, num_classes, num_steps, schedule, start, end):\n",
    "    '''\n",
    "    Calculates the loss associated with the model's prediction of the data. \n",
    "    This fn is given a batch of data with associated labels. \n",
    "    '''\n",
    "    batch_size = x.shape[0]\n",
    "    # x = x.reshape(batch_size, -1)\n",
    "    x = rescale_to_neg_one_to_one(x)\n",
    "    \n",
    "    # add noise to the data\n",
    "    # t = torch.randint(0, num_steps, size=(batch_size,), device=device).long()\n",
    "    # x_noisy = generate_many_noisy_samples(num_steps, x, t, schedule, start, end, device).reshape(batch_size, -1)\n",
    "    # x_noisy = generate_many_noisy_samples(num_steps, x, t, schedule, start, end, device)\n",
    "    \n",
    "    # output = model(x_noisy, t)  # the output is from a softmax, so it produces a probability of each discrete class\n",
    "    output = model(x)  # the output is from a softmax, so it produces a probability of each discrete class\n",
    "    c = torch.nn.functional.one_hot(labels, num_classes).to(torch.float)  # encodes the classes with a one hot encoding\n",
    "    \n",
    "    loss = (c - output).square().mean()\n",
    "    # loss = torch.nn.functional.cross_entropy(output, c)\n",
    "    return loss\n",
    "\n",
    "from models import NetWithNoiseInfo, NetNoNoiseInfo\n",
    "classifier = NetNoNoiseInfo(norm_method='nn', num_channels=description['num_hidden'], num_steps=description['num_steps'])\n",
    "# classifier = NetWithNoiseInfo(norm_method='nn', num_channels=description['num_hidden'], num_steps=description['num_steps'])\n",
    "classifier.to(device)\n",
    "classifier.train()\n",
    "num_epochs = int(description['num_epochs'])\n",
    "\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=description['lr'])\n",
    "\n",
    "run_dir = os.path.join(base_dir, 'demos/runs', f'{description[\"model_name\"]}_{description[\"model_num\"]}')\n",
    "tb = SummaryWriter(run_dir, flush_secs=1)\n",
    "\n",
    "for epoch in tqdm(range(1, int(num_epochs) + 1), total=int(num_epochs), desc='Training model', unit='epochs', miniters=int(num_epochs)/100, maxinterval=float(\"inf\")):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        loss = classifier_loss(classifier, data, target, 10, description['num_steps'], description['schedule'], description['start'], description['end'])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tb.add_scalar('Loss', loss.item(), epoch+batch_idx)\n",
    "\n",
    "print('training is over at last')\n",
    "\n",
    "# save model weights\n",
    "from utils import save_model_weights\n",
    "save_model_weights(classifier, description['model_name'], description['model_num'])\n",
    "tb.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs tensor([[0.0938, 0.0878, 0.1031, 0.0873, 0.1008, 0.0892, 0.1103, 0.1222, 0.1028,\n",
      "         0.1027],\n",
      "        [0.0934, 0.1011, 0.1032, 0.0958, 0.1184, 0.0912, 0.0954, 0.1101, 0.0918,\n",
      "         0.0997],\n",
      "        [0.0876, 0.1002, 0.0994, 0.0846, 0.1113, 0.1032, 0.1007, 0.1133, 0.1064,\n",
      "         0.0932],\n",
      "        [0.0866, 0.0968, 0.1116, 0.0806, 0.1121, 0.1030, 0.1014, 0.1146, 0.1003,\n",
      "         0.0930],\n",
      "        [0.0873, 0.0930, 0.1059, 0.0794, 0.1099, 0.1031, 0.0949, 0.1315, 0.1000,\n",
      "         0.0948],\n",
      "        [0.0902, 0.0976, 0.0978, 0.0955, 0.1085, 0.0973, 0.0957, 0.1174, 0.0938,\n",
      "         0.1062],\n",
      "        [0.0899, 0.1007, 0.0915, 0.0958, 0.0996, 0.1088, 0.0919, 0.1300, 0.0956,\n",
      "         0.0962],\n",
      "        [0.0898, 0.0907, 0.1024, 0.0910, 0.1185, 0.0952, 0.1060, 0.1231, 0.0941,\n",
      "         0.0891],\n",
      "        [0.0879, 0.0944, 0.1008, 0.0885, 0.1134, 0.0953, 0.1079, 0.1144, 0.0970,\n",
      "         0.1006],\n",
      "        [0.0885, 0.1072, 0.1020, 0.0892, 0.1052, 0.0988, 0.1045, 0.1198, 0.0916,\n",
      "         0.0932]], device='cuda:0', grad_fn=<SliceBackward0>)\n",
      "predictions: tensor([7, 4, 7, 7, 7, 7, 7, 7, 7, 7], device='cuda:0')\n",
      "correct: tensor([3, 5, 8, 8, 5, 5, 7, 4, 6, 3], device='cuda:0')\n",
      "0.12\n"
     ]
    }
   ],
   "source": [
    "# test the model performance\n",
    "from utils import load_model_weights\n",
    "from image_utils import generate_many_noisy_samples\n",
    "model_name = 'large-noisy-image-classifier'\n",
    "model_num = 5\n",
    "\n",
    "desc_dir = os.path.join(base_dir, 'core', 'model_description', f'{model_name}_{model_num}.json')\n",
    "# load json file form desc_dir\n",
    "with open(desc_dir, 'r') as f:\n",
    "    description = json.load(f)\n",
    "\n",
    "# load model weights\n",
    "load_model = True\n",
    "\n",
    "if load_model == True:\n",
    "    from models import LargeNoisyImageClassifier, NetNoNoiseInfo\n",
    "    # model = LargeNoisyImageClassifier(num_in=description['num_in'], num_hidden=description['num_hidden'], num_classes=10, num_steps=description['num_steps'])\n",
    "    model = NetNoNoiseInfo(norm_method='nn', num_channels=description['num_hidden'])\n",
    "    model = model.to(device)\n",
    "    from utils import load_model_weights\n",
    "    model_name = f\"{description['model_name']}_{description['model_num']}.pt\"\n",
    "    loadpath = os.path.join(base_dir, f'core/saved_weights', model_name)\n",
    "    state_dict = torch.load(loadpath, map_location=device)\n",
    "    # model = load_model_weights(model, description['model_name'], description['model_num'], device)\n",
    "    # model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "# load data\n",
    "def test_classifier_accuracy(model, num_test_samples,):\n",
    "    import torch\n",
    "    from torchvision import datasets, transforms\n",
    "    mnist_dir = os.path.join(base_dir, 'core', 'datasets', 'mnist')\n",
    "    mnist_test = datasets.MNIST(mnist_dir, train=False, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                    ]))\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        mnist_test,\n",
    "        batch_size=num_test_samples, shuffle=True)\n",
    "\n",
    "    # test the model\n",
    "    from image_utils import get_classifier_acc\n",
    "\n",
    "    for batch_idx, (test_data, test_targets) in enumerate(test_loader):\n",
    "        test_data = test_data.to(device)\n",
    "        test_data = rescale_to_neg_one_to_one(test_data)\n",
    "        test_targets = test_targets.to(device)\n",
    "        \n",
    "        # add noise to image\n",
    "        \n",
    "        testset_size = test_data.shape[0]\n",
    "        t = torch.tensor([0])\n",
    "        t = t.repeat(testset_size,).long().cuda()\n",
    "        probs = model(test_data)\n",
    "        pred = probs.max(dim=1)[1]\n",
    "        print('probs', probs[:10])\n",
    "        print(f'predictions: {pred[:10]}')\n",
    "        print(f'correct: {test_targets[:10]}')\n",
    "        \n",
    "        num_correct = pred.eq(test_targets.view_as(pred)).sum().item()\n",
    "        \n",
    "        acc = num_correct / testset_size\n",
    "        print(acc)\n",
    "        break\n",
    "\n",
    "test_classifier_accuracy(model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuvenvkernel2",
   "language": "python",
   "name": "gpuvenvkernel2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
