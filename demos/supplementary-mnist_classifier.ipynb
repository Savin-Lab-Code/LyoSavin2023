{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import json\n",
    "\n",
    "project_root = os.path.abspath(\"\")  # alternative\n",
    "if project_root[-12:] == 'LyoSavin2023':\n",
    "    base_dir = project_root\n",
    "else:\n",
    "    base_dir = os.path.dirname(project_root)\n",
    "sys.path.append(os.path.join(base_dir, 'core'))\n",
    "sys.path.append(os.path.join(base_dir, 'core/utils'))\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from utils import remove_all_ticks_and_labels\n",
    "\n",
    "global device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Net\n",
    "\n",
    "description = {\n",
    "    'model_name': 'large-noisy-image-classifier',\n",
    "    'model_num': 4,\n",
    "    'num_hidden': 32,\n",
    "    'dataset': 'mnist',\n",
    "    'num_epochs': 2e2,\n",
    "    'lr': 4e-3,\n",
    "    'num_steps': 150,\n",
    "    'batch_size': 512,\n",
    "    'num_in': 28*28,\n",
    "    'schedule': 'sigmoid',\n",
    "    'start': 1e-7,\n",
    "    'end': 1e-1,\n",
    "}\n",
    "# save description\n",
    "with open(os.path.join(base_dir, 'core', 'model_description', f'{description[\"model_name\"]}_{description[\"model_num\"]}.json'), 'w') as f:\n",
    "    json.dump(description, f)\n",
    "\n",
    "classifier = Net(norm_method='nn', num_channels=description['num_hidden'], num_steps=description['num_steps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv_1): Conv2d(1, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
       "  (relu): ReLU()\n",
       "  (conv_2): Conv2d(32, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc_1): Linear(in_features=500, out_features=10, bias=True)\n",
       "  (embed): Embedding(150, 32)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "mnist_dir = os.path.join(base_dir, 'core', 'datasets', 'mnist')\n",
    "\n",
    "mnist_train = datasets.MNIST(mnist_dir, train=True, download=True,\n",
    "                transform=transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # transforms.Normalize((0.1307,), (0.3081,))\n",
    "                ]))\n",
    "\n",
    "# mnist_train.targets\n",
    "print(mnist_train[0][1])\n",
    "\n",
    "# ------------------------------- select digits ------------------------------ #\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    mnist_train,\n",
    "    batch_size=description['batch_size'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7766802adb4940c79ae58708ccdbfa9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training model:   0%|          | 0/200 [00:00<?, ?epochs/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training is over at last\n",
      "model state dict saved in directory: /mnt/ceph/users/blyo1/projects/LyoSavin2023/core/saved_weights/large-noisy-image-classifier_4.pt\n"
     ]
    }
   ],
   "source": [
    "# training \n",
    "from image_utils import generate_many_noisy_samples, rescale_to_neg_one_to_one\n",
    "global device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}', flush=True)\n",
    "\n",
    "def classifier_loss(model, x, labels, num_classes, num_steps, schedule, start, end):\n",
    "    '''\n",
    "    Calculates the loss associated with the model's prediction of the data. \n",
    "    This fn is given a batch of data with associated labels. \n",
    "    '''\n",
    "    batch_size = x.shape[0]\n",
    "    # x = x.reshape(batch_size, -1)\n",
    "    x = rescale_to_neg_one_to_one(x)\n",
    "    \n",
    "    # add noise to the data\n",
    "    t = torch.randint(0, num_steps, size=(batch_size,), device=device).long()\n",
    "    # x_noisy = generate_many_noisy_samples(num_steps, x, t, schedule, start, end, device).reshape(batch_size, -1)\n",
    "    x_noisy = generate_many_noisy_samples(num_steps, x, t, schedule, start, end, device)\n",
    "    \n",
    "    output = model(x_noisy, t)  # the output is from a softmax, so it produces a probability of each discrete class\n",
    "    # output = model(x_noisy)  # the output is from a softmax, so it produces a probability of each discrete class\n",
    "    c = torch.nn.functional.one_hot(labels, num_classes).to(torch.float)  # encodes the classes with a one hot encoding\n",
    "    \n",
    "    # loss = (c - output).square().mean()\n",
    "    loss = torch.nn.functional.cross_entropy(output, c)\n",
    "    return loss\n",
    "\n",
    "\n",
    "classifier.to(device)\n",
    "classifier.train()\n",
    "num_epochs = int(description['num_epochs'])\n",
    "\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=description['lr'])\n",
    "\n",
    "run_dir = os.path.join(base_dir, 'demos/runs', f'{description[\"model_name\"]}_{description[\"model_num\"]}')\n",
    "tb = SummaryWriter(run_dir, flush_secs=1)\n",
    "\n",
    "for epoch in tqdm(range(1, int(num_epochs) + 1), total=int(num_epochs), desc='Training model', unit='epochs', miniters=int(num_epochs)/100, maxinterval=float(\"inf\")):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        loss = classifier_loss(classifier, data, target, 10, description['num_steps'], description['schedule'], description['start'], description['end'])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tb.add_scalar('Loss', loss.item(), epoch+batch_idx)\n",
    "\n",
    "print('training is over at last')\n",
    "\n",
    "# save model weights\n",
    "from utils import save_model_weights\n",
    "save_model_weights(classifier, description['model_name'], description['model_num'])\n",
    "tb.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: tensor([3, 6, 6, 3, 3, 9, 3, 3, 9, 3], device='cuda:0')\n",
      "correct: tensor([6, 3, 2, 8, 4, 8, 1, 6, 2, 1], device='cuda:0')\n",
      "0.03\n"
     ]
    }
   ],
   "source": [
    "# test the model performance\n",
    "from utils import load_model_weights\n",
    "from image_utils import generate_many_noisy_samples\n",
    "model_name = 'large-noisy-image-classifier'\n",
    "model_num = 4\n",
    "\n",
    "desc_dir = os.path.join(base_dir, 'core', 'model_description', f'{model_name}_{model_num}.json')\n",
    "# load json file form desc_dir\n",
    "with open(desc_dir, 'r') as f:\n",
    "    description = json.load(f)\n",
    "\n",
    "# load model weights\n",
    "load_model = True\n",
    "\n",
    "if load_model == True:\n",
    "    from models import LargeNoisyImageClassifier, Net\n",
    "    # model = LargeNoisyImageClassifier(num_in=description['num_in'], num_hidden=description['num_hidden'], num_classes=10, num_steps=description['num_steps'])\n",
    "    model = Net(norm_method='nn', num_channels=description['num_hidden'])\n",
    "    model = model.to(device)\n",
    "    from utils import load_model_weights\n",
    "    model_name = f\"{description['model_name']}_{description['model_num']}.pt\"\n",
    "    loadpath = os.path.join(base_dir, f'core/saved_weights', model_name)\n",
    "    state_dict = torch.load(loadpath, map_location=device)\n",
    "    # model = load_model_weights(model, description['model_name'], description['model_num'], device)\n",
    "    # model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "# load data\n",
    "def test_classifier_accuracy(model, num_test_samples,):\n",
    "    import torch\n",
    "    from torchvision import datasets, transforms\n",
    "    mnist_dir = os.path.join(base_dir, 'core', 'datasets', 'mnist')\n",
    "    mnist_test = datasets.MNIST(mnist_dir, train=False, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                    ]))\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        mnist_test,\n",
    "        batch_size=num_test_samples, shuffle=True)\n",
    "\n",
    "    # test the model\n",
    "    from image_utils import get_classifier_acc\n",
    "\n",
    "    for batch_idx, (test_data, test_targets) in enumerate(test_loader):\n",
    "        test_data = test_data.to(device)\n",
    "        # add noise to image\n",
    "        \n",
    "        test_targets = test_targets.to(device)\n",
    "        acc = get_classifier_acc(model, test_data, test_targets)\n",
    "        print(acc)\n",
    "        break\n",
    "\n",
    "test_classifier_accuracy(model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuvenvkernel2",
   "language": "python",
   "name": "gpuvenvkernel2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
