{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "\n",
    "project_root = os.path.abspath(\"\")  # alternative\n",
    "if project_root[-12:] == 'LyoSavin2023':\n",
    "    base_dir = project_root\n",
    "else:\n",
    "    base_dir = os.path.dirname(project_root)\n",
    "sys.path.append(os.path.join(base_dir, 'core'))\n",
    "sys.path.append(os.path.join(base_dir, 'core/utils'))\n",
    "\n",
    "import torch\n",
    "from tqdm.auto import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import zarr\n",
    "\n",
    "from utils import remove_all_ticks_and_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training a model during the oscillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, \n",
    "                model_name, \n",
    "                model_number, \n",
    "                num_steps, \n",
    "                forward_schedule,\n",
    "                num_hidden, \n",
    "                num_dims,\n",
    "                num_epochs,\n",
    "                batch_size,\n",
    "                lr,\n",
    "                device,\n",
    "                dataset,\n",
    "                pretrained_model):\n",
    "\n",
    "    # beta-related parameters\n",
    "    from prior_utils import forward_process\n",
    "    from utils import noise_estimation_loss\n",
    "    \n",
    "    coefs = forward_process(num_steps, device, forward_schedule)\n",
    "    betas, alphas, alphas_prod, alphas_prod_p, alphas_bar_sqrt, one_minus_alphas_prod_log, one_minus_alphas_prod_sqrt = coefs\n",
    "    alphas_bar_sqrt = alphas_bar_sqrt.to(device)\n",
    "    one_minus_alphas_prod_sqrt = one_minus_alphas_prod_sqrt.to(device)\n",
    "    \n",
    "    # training set\n",
    "    dataset = dataset.to(device)\n",
    "    \n",
    "    print('model_name:', model_name)\n",
    "    print('model_number:', model_number)\n",
    "    print('num_steps:', num_steps)\n",
    "    print('forward_schedule:', forward_schedule)\n",
    "    print('num_hidden:', num_hidden)\n",
    "    print('num_epochs:', num_epochs)\n",
    "    print('dataset shape:', dataset.shape)\n",
    "    \n",
    "    # define model\n",
    "    if pretrained_model['use_pretrained_model_weights']:\n",
    "        if pretrained_model['use_checkpoint_weights']==False:\n",
    "            from utils import load_model_weights\n",
    "            pretrained_model_name = pretrained_model['model_name']\n",
    "            pretrained_model_num = pretrained_model['model_num']\n",
    "            print(f'taking weights from pretrained model {pretrained_model_name}_{pretrained_model_num}!')\n",
    "            model = load_model_weights(model, pretrained_model_name, pretrained_model_num, device)\n",
    "        elif pretrained_model['use_checkpoint_weights']==True:\n",
    "            from utils import load_model_weights_from_chkpt\n",
    "            model, num_steps, ambient_dims = load_model_weights_from_chkpt(pretrained_model['model_name'], pretrained_model['model_num'], epoch_number=pretrained_model['checkpoint_epoch'], device=device)\n",
    "            print('model weights loaded from checkpoint!', flush=True)\n",
    "            \n",
    "    model.to(device)\n",
    "\n",
    "    # training parameteres\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    if pretrained_model['use_pretrained_model_weights'] and pretrained_model['use_checkpoint_weights']==True:\n",
    "        from utils import load_optimizer_state_dict\n",
    "        optimizer = load_optimizer_state_dict(optimizer, pretrained_model['model_name'], pretrained_model['model_num'], epoch_number=pretrained_model['checkpoint_epoch'], device=device)\n",
    "        print('optimizer state dict loaded from checkpoint!', flush=True)\n",
    "\n",
    "    run_dir = os.path.join(base_dir, 'demos/runs', f'{model_name}_{model_number}')\n",
    "    tb = SummaryWriter(run_dir)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # start training\n",
    "    model.train()\n",
    "    for t in tqdm(range(int(num_epochs)), total=int(num_epochs), desc='Training model', unit='epochs', miniters=int(num_epochs)/1000, maxinterval=float(\"inf\")):\n",
    "        permutation = torch.randperm(dataset.size()[0], device=device)\n",
    "    \n",
    "        for i in range(0, dataset.size()[0], batch_size):\n",
    "            # retrieve current batch\n",
    "            indices = permutation[i:i+batch_size]\n",
    "            batch_x = dataset[indices]\n",
    "            \n",
    "            # compute the loss\n",
    "            loss = noise_estimation_loss(model, batch_x, num_steps, alphas_bar_sqrt, one_minus_alphas_prod_sqrt, device, norm='l2', has_class_label=False)\n",
    "            # zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # backward pass: compute the gradient of the loss wrt the parameters\n",
    "            loss.backward()\n",
    "            # call the step function to update the parameters\n",
    "            optimizer.step()\n",
    "        \n",
    "        if t <= int(2e5):\n",
    "            if t % int(1e4) == 0:\n",
    "                save_checkpoint(t, model.state_dict(), optimizer.state_dict(), loss.item(), model_name, model_number)\n",
    "        else:\n",
    "            if t % int(1e5) == 0:\n",
    "                save_checkpoint(t, model.state_dict(), optimizer.state_dict(), loss.item(), model_name, model_number)\n",
    "        \n",
    "        # write to tensorboard\n",
    "        tb.add_scalar('Loss', loss.item(), t)\n",
    "    tb.flush()\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    duration_mins = duration / 60\n",
    "    print(f'training took {duration:.0f} seconds, which is {duration_mins:.2f} minutes.')\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
